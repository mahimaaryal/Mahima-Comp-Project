{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8c08a1-6e7f-40e5-bee9-a74cc88d8db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import warnings\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650dc1e7-c385-4aa2-970b-aa744b69c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e00208f-41c3-484d-8dca-e2b4abfcc2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 42)\n",
      "Dimensions of the Test set: (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "\n",
    "train = pd.read_csv(train_url,header=None, names = col_names)\n",
    "\n",
    "test = pd.read_csv(test_url, header=None, names = col_names)\n",
    "\n",
    "print('Dimensions of the Training set:',train.shape)\n",
    "print('Dimensions of the Test set:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2729155-3ae9-4e96-b126-b588cde8dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   duration                     125973 non-null  int64  \n",
      " 1   protocol_type                125973 non-null  object \n",
      " 2   service                      125973 non-null  object \n",
      " 3   flag                         125973 non-null  object \n",
      " 4   src_bytes                    125973 non-null  int64  \n",
      " 5   dst_bytes                    125973 non-null  int64  \n",
      " 6   land                         125973 non-null  int64  \n",
      " 7   wrong_fragment               125973 non-null  int64  \n",
      " 8   urgent                       125973 non-null  int64  \n",
      " 9   hot                          125973 non-null  int64  \n",
      " 10  num_failed_logins            125973 non-null  int64  \n",
      " 11  logged_in                    125973 non-null  int64  \n",
      " 12  num_compromised              125973 non-null  int64  \n",
      " 13  root_shell                   125973 non-null  int64  \n",
      " 14  su_attempted                 125973 non-null  int64  \n",
      " 15  num_root                     125973 non-null  int64  \n",
      " 16  num_file_creations           125973 non-null  int64  \n",
      " 17  num_shells                   125973 non-null  int64  \n",
      " 18  num_access_files             125973 non-null  int64  \n",
      " 19  num_outbound_cmds            125973 non-null  int64  \n",
      " 20  is_host_login                125973 non-null  int64  \n",
      " 21  is_guest_login               125973 non-null  int64  \n",
      " 22  count                        125973 non-null  int64  \n",
      " 23  srv_count                    125973 non-null  int64  \n",
      " 24  serror_rate                  125973 non-null  float64\n",
      " 25  srv_serror_rate              125973 non-null  float64\n",
      " 26  rerror_rate                  125973 non-null  float64\n",
      " 27  srv_rerror_rate              125973 non-null  float64\n",
      " 28  same_srv_rate                125973 non-null  float64\n",
      " 29  diff_srv_rate                125973 non-null  float64\n",
      " 30  srv_diff_host_rate           125973 non-null  float64\n",
      " 31  dst_host_count               125973 non-null  int64  \n",
      " 32  dst_host_srv_count           125973 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
      " 37  dst_host_serror_rate         125973 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
      " 39  dst_host_rerror_rate         125973 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
      " 41  label                        125973 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97797f10-2b8e-40f7-a002-362f2f2ee27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22544 entries, 0 to 22543\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     22544 non-null  int64  \n",
      " 1   protocol_type                22544 non-null  object \n",
      " 2   service                      22544 non-null  object \n",
      " 3   flag                         22544 non-null  object \n",
      " 4   src_bytes                    22544 non-null  int64  \n",
      " 5   dst_bytes                    22544 non-null  int64  \n",
      " 6   land                         22544 non-null  int64  \n",
      " 7   wrong_fragment               22544 non-null  int64  \n",
      " 8   urgent                       22544 non-null  int64  \n",
      " 9   hot                          22544 non-null  int64  \n",
      " 10  num_failed_logins            22544 non-null  int64  \n",
      " 11  logged_in                    22544 non-null  int64  \n",
      " 12  num_compromised              22544 non-null  int64  \n",
      " 13  root_shell                   22544 non-null  int64  \n",
      " 14  su_attempted                 22544 non-null  int64  \n",
      " 15  num_root                     22544 non-null  int64  \n",
      " 16  num_file_creations           22544 non-null  int64  \n",
      " 17  num_shells                   22544 non-null  int64  \n",
      " 18  num_access_files             22544 non-null  int64  \n",
      " 19  num_outbound_cmds            22544 non-null  int64  \n",
      " 20  is_host_login                22544 non-null  int64  \n",
      " 21  is_guest_login               22544 non-null  int64  \n",
      " 22  count                        22544 non-null  int64  \n",
      " 23  srv_count                    22544 non-null  int64  \n",
      " 24  serror_rate                  22544 non-null  float64\n",
      " 25  srv_serror_rate              22544 non-null  float64\n",
      " 26  rerror_rate                  22544 non-null  float64\n",
      " 27  srv_rerror_rate              22544 non-null  float64\n",
      " 28  same_srv_rate                22544 non-null  float64\n",
      " 29  diff_srv_rate                22544 non-null  float64\n",
      " 30  srv_diff_host_rate           22544 non-null  float64\n",
      " 31  dst_host_count               22544 non-null  int64  \n",
      " 32  dst_host_srv_count           22544 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       22544 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       22544 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  22544 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  22544 non-null  float64\n",
      " 37  dst_host_serror_rate         22544 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     22544 non-null  float64\n",
      " 39  dst_host_rerror_rate         22544 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     22544 non-null  float64\n",
      " 41  label                        22544 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c77c168-1ef8-4cd6-8fd0-eb594ca9d84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Training set:\n",
      "label\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution Test set:\n",
      "label\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Training set:')\n",
    "print(train['label'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a9b062-a2ef-4cfe-ba50-82a4a28fb60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "normal       67343\n",
      "anomalous    58630\n",
      "Name: count, dtype: int64\n",
      "\n",
      "label\n",
      "anomalous    12833\n",
      "normal        9711\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Rewriting\n",
    "train[\"label\"] = train[\"label\"].apply(lambda x: \"normal\" if x == \"normal\" else \"anomalous\")\n",
    "test[\"label\"] = test[\"label\"].apply(lambda x: \"normal\" if x == \"normal\" else \"anomalous\")\n",
    "# Checking the distribution after the change\n",
    "print(train[\"label\"].value_counts())\n",
    "print()\n",
    "print(test[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f0a59e6-0d3c-4c0a-b1a9-6e3e37363275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing columns: [] \n"
     ]
    }
   ],
   "source": [
    "missing_columns= [col for col in train.columns if train[col].isnull().sum() > 0]\n",
    "print(f\"Number of missing columns: {missing_columns} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d6e38d-bb45-4e23-a611-f6f23982f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of the dataset: (125964, 42)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "train.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check the shape of the dataset after removing duplicates\n",
    "print(f\"New shape of the dataset: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29703f15-8e9c-413c-8c81-ab0f808a1ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing columns: [] \n"
     ]
    }
   ],
   "source": [
    "missing_columns= [col for col in test.columns if test[col].isnull().sum() > 0]\n",
    "print(f\"Number of missing columns: {missing_columns} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b000c6b0-8afc-41c0-8a0b-ef39a3ab7318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicate rows: {test.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21673f0d-278c-4b36-9a5e-ab35a8f9646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of the dataset: (22541, 42)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "test.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check the shape of the dataset after removing duplicates\n",
    "print(f\"New shape of the dataset: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4755f0ac-a098-4498-b42a-e1b36fa3cff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c858b62-42a1-44b8-9e52-d73b00066ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the same value across all rows: ['num_outbound_cmds']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "def check_constant_columns(test):\n",
    "    constant_columns = [col for col in test.columns if test[col].nunique() == 1]\n",
    "    return constant_columns\n",
    "\n",
    "# Example usage\n",
    "constant_cols = check_constant_columns(test)\n",
    "if constant_cols:\n",
    "    print(f\"Columns with the same value across all rows: {constant_cols}\")\n",
    "else:\n",
    "    print(\"No columns have the same value across all rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73620b26-3bff-4610-b3d7-8161099ca762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "22539    0\n",
       "22540    0\n",
       "22541    0\n",
       "22542    0\n",
       "22543    0\n",
       "Name: num_outbound_cmds, Length: 22541, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"num_outbound_cmds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7417e6d5-573a-4f52-aae5-a97176899ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "test.drop(['num_outbound_cmds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0b293fb-d6ab-4835-bfa4-96cd05e81206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125964</td>\n",
       "      <td>125964</td>\n",
       "      <td>125964</td>\n",
       "      <td>125964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>102689</td>\n",
       "      <td>40338</td>\n",
       "      <td>74936</td>\n",
       "      <td>67343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       protocol_type service    flag   label\n",
       "count         125964  125964  125964  125964\n",
       "unique             3      70      11       2\n",
       "top              tcp    http      SF  normal\n",
       "freq          102689   40338   74936   67343"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f74387-d4c6-41cd-b7e4-7783d5066849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22541</td>\n",
       "      <td>22541</td>\n",
       "      <td>22541</td>\n",
       "      <td>22541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>anomalous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>18877</td>\n",
       "      <td>7853</td>\n",
       "      <td>14875</td>\n",
       "      <td>12830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       protocol_type service   flag      label\n",
       "count          22541   22541  22541      22541\n",
       "unique             3      64     11          2\n",
       "top              tcp    http     SF  anomalous\n",
       "freq           18877    7853  14875      12830"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee2dd98-a796-4431-8a01-79ce1046307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "def LabelEncoding(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "                label_encoder = LabelEncoder()\n",
    "                df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "LabelEncoding(train)\n",
    "LabelEncoding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cad41ca-1748-4ca8-b5fe-191a98e22557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: protocol_type, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"protocol_type\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dee2d52-a1c8-441f-85be-232511d20470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.588217026751253"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ddec6a7-70f9-4869-afee-bcd44b9484f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Training Dataset into X_train (features) and y_train (label)\n",
    "X_train = train.drop([\"label\"], axis=1)\n",
    "y_train = train[\"label\"]\n",
    "X_test = test.drop([\"label\"], axis=1)\n",
    "y_test = test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4976129-17bb-4e5a-9af0-00f6a897b1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125964, 40)\n",
      "(22541, 40)\n",
      "(125964,)\n",
      "(22541,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.shape}\")\n",
    "print(f\"{X_test.shape}\")\n",
    "print(f\"{y_train.shape}\")\n",
    "print(f\"{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e1cdb7e-1cce-469b-8e35-a75eed772460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "rfc = RandomForestClassifier() \n",
    "\n",
    "rfe = RFE(rfc, n_features_to_select=10)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d3fa96a-8959-46de-89d8-aa42fd7638e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type',\n",
       " 'service',\n",
       " 'flag',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'count',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools \n",
    "from tabulate import tabulate\n",
    "\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), X_train.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b688fe5f-7fee-4402-8cc5-c5f78bc88b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1906.66s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e149e69-7c88-469b-8bd8-f8e2450cf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[selected_features]\n",
    "# Training dataset is updated to include only the selected features (10 features chosen by RFE)\n",
    "X_test = X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdc468dc-e7fd-408f-b334-4e6e6d9abf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0e+00, 2.0e+01, 9.0e+00, ..., 0.0e+00, 2.5e+01, 1.7e-01],\n",
       "       [2.0e+00, 4.4e+01, 9.0e+00, ..., 1.5e-01, 1.0e+00, 0.0e+00],\n",
       "       [1.0e+00, 4.9e+01, 5.0e+00, ..., 7.0e-02, 2.6e+01, 1.0e-01],\n",
       "       ...,\n",
       "       [1.0e+00, 5.4e+01, 9.0e+00, ..., 0.0e+00, 3.0e+01, 1.2e-01],\n",
       "       [1.0e+00, 3.0e+01, 5.0e+00, ..., 5.0e-02, 8.0e+00, 3.0e-02],\n",
       "       [1.0e+00, 2.0e+01, 9.0e+00, ..., 0.0e+00, 7.7e+01, 3.0e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3645d05-42d1-4f77-92f7-9a13dfa017b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  3.372988224029541\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "start_time = time.time()\n",
    "\n",
    "#Fitting the model to the data \n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training time: \", end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03f83ece-7ca5-44b5-83df-2c65d7bcf975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time:  0.15715312957763672\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Compare predictions to truth labels to evaluate the model\n",
    "y_preds = clf.predict(X_test)\n",
    "end_time = time.time()\n",
    "print(\"Testing time: \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "522c853f-5090-47cb-b190-c814e7821443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888292444878222"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b363277-9fdf-450c-92e4-5e7f82884697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999285510145756"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2189ff14-b975-4704-b175-77d4b6342c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888292444878222"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2c72751-48cc-4628-a617-4b91537e1166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best cross-validation score for Gradient Boosting: 0.9984439999356131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:01:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:02:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:02:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:02:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:02:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:02:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:02:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:04:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:04:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:04:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:04:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:04:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:04:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:05:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:05:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:05:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:05:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:05:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:06:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:07:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:07:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:07:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:07:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:07:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:07:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:08:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:08:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:08:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:08:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:08:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:09:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:10:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:10:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:10:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:10:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [16:10:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Cross-Validation Score: 0.9986504089981393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Gradient Boosting Model with hyperparameter tuning\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "param_grid_gbc = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5],\n",
    "}\n",
    "grid_gbc = GridSearchCV(gbc, param_grid_gbc, cv=5)\n",
    "grid_gbc.fit(X_train, y_train)\n",
    "print(\"Best parameters for Gradient Boosting:\", grid_gbc.best_params_)\n",
    "print(\"Best cross-validation score for Gradient Boosting:\", grid_gbc.best_score_)\n",
    "\n",
    "# Stacking Ensemble\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gbc', grid_gbc.best_estimator_),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42))\n",
    "]\n",
    "\n",
    "stacked_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacked_model.fit(X_train, y_train)\n",
    "stacked_score = cross_val_score(stacked_model, X_train, y_train, cv=5).mean()\n",
    "print(\"Stacked Model Cross-Validation Score:\", stacked_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6227fa9-abbe-463a-a486-7999ae4d9038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888292444878222"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84e6a19c-f46e-4548-a6b1-6dfbe3f0d4ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 23\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m test \u001b[38;5;241m=\u001b[39m preprocess_data(test)\n\u001b[1;32m     26\u001b[0m X_train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[42], line 18\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(df):\n\u001b[1;32m     17\u001b[0m     label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m---> 18\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomalous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprotocol_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflag\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# One-hot encoding for categorical\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load your dataset (use your dataset URL or local path)\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "train = pd.read_csv(train_url)\n",
    "test = pd.read_csv(test_url)\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = df['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "    df = pd.get_dummies(df, columns=['protocol_type', 'service', 'flag'])  # One-hot encoding for categorical\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "    return df\n",
    "\n",
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)\n",
    "\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Feature Mapping (Random Feature Transformation)\n",
    "def feature_mapping(X, n_nodes=1000):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes)\n",
    "    Z = np.dot(X, W) + bias  # Linear mapping\n",
    "    return np.tanh(Z)  # Non-linear transformation\n",
    "\n",
    "# Enhancement Nodes (Adding randomness to enhance features)\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes)\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    return np.tanh(enhancement)\n",
    "\n",
    "# BLS Training\n",
    "def train_bls(X, y, n_mapped=1000, n_enhancement=500, reg=0.01):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    \n",
    "    # Concatenate original features with enhanced features\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    \n",
    "    # Ridge regression for final output layer\n",
    "    model = Ridge(alpha=reg, fit_intercept=False)\n",
    "    model.fit(bls_features, y)\n",
    "    return model, mapped_features, enhanced_features\n",
    "\n",
    "# BLS Prediction\n",
    "def predict_bls(model, X, mapped_features, enhanced_features):\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    return model.predict(bls_features)\n",
    "\n",
    "# Training and Prediction\n",
    "model, mapped_features_train, enhanced_features_train = train_bls(X_train, y_train)\n",
    "y_pred_train = predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
    "y_pred_train = np.where(y_pred_train >= 0.5, 1, 0)  # Convert probabilities to binary class\n",
    "\n",
    "# Evaluation\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Testing the model\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=1000)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=500)\n",
    "y_pred_test = predict_bls(model, X_test, mapped_features_test, enhanced_features_test)\n",
    "y_pred_test = np.where(y_pred_test >= 0.5, 1, 0)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e294c65a-5ec6-4b71-bc1d-1ad0743932ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0', 'tcp', 'ftp_data', 'SF', '491', '0.1', '0.2', '0.3', '0.4', '0.5',\n",
      "       '0.6', '0.7', '0.8', '0.9', '0.10', '0.11', '0.12', '0.13', '0.14',\n",
      "       '0.15', '0.16', '0.18', '2', '2.1', '0.19', '0.20', '0.21', '0.22', '1',\n",
      "       '0.23', '0.24', '150', '25', '0.17', '0.03', '0.17.1', '0.25', '0.26',\n",
      "       '0.27', '0.05', '0.28', 'normal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05f34c7a-5383-4478-aa08-0ee56596f792",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['protocol_type', 'service', 'flag'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Apply preprocessing\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m test \u001b[38;5;241m=\u001b[39m preprocess_data(test)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Split data into features and labels\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[44], line 22\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     20\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     21\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomalous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprotocol_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mservice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# One-hot encoding for categorical\u001b[39;00m\n\u001b[1;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/pandas/core/reshape/encoding.py:169\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['protocol_type', 'service', 'flag'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load your dataset\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "train = pd.read_csv(train_url)\n",
    "test = pd.read_csv(test_url)\n",
    "\n",
    "# Rename the last column to 'label' to match the code requirements\n",
    "train = train.rename(columns={'normal': 'label'})\n",
    "test = test.rename(columns={'normal': 'label'})\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = df['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "    df = pd.get_dummies(df, columns=['protocol_type', 'service', 'flag'])  # One-hot encoding for categorical\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)\n",
    "\n",
    "# Split data into features and labels\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Define the feature mapping function\n",
    "def feature_mapping(X, n_nodes=1000):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes)\n",
    "    Z = np.dot(X, W) + bias  # Linear mapping\n",
    "    return np.tanh(Z)  # Non-linear transformation\n",
    "\n",
    "# Define the enhancement nodes function\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes)\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    return np.tanh(enhancement)\n",
    "\n",
    "# Define the BLS training function\n",
    "def train_bls(X, y, n_mapped=1000, n_enhancement=500, reg=0.01):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    \n",
    "    # Concatenate original features with enhanced features\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    \n",
    "    # Ridge regression for final output layer\n",
    "    model = Ridge(alpha=reg, fit_intercept=False)\n",
    "    model.fit(bls_features, y)\n",
    "    return model, mapped_features, enhanced_features\n",
    "\n",
    "# Define the BLS prediction function\n",
    "def predict_bls(model, X, mapped_features, enhanced_features):\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    return model.predict(bls_features)\n",
    "\n",
    "# Train the BLS model\n",
    "model, mapped_features_train, enhanced_features_train = train_bls(X_train, y_train)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_pred_train = predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
    "y_pred_train = np.where(y_pred_train >= 0.5, 1, 0)  # Convert probabilities to binary class\n",
    "\n",
    "# Evaluate training accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test the model\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=1000)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=500)\n",
    "y_pred_test = predict_bls(model, X_test, mapped_features_test, enhanced_features_test)\n",
    "y_pred_test = np.where(y_pred_test >= 0.5, 1, 0)\n",
    "\n",
    "# Evaluate test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2918f076-ffb1-45f0-aacd-954fa4cbf256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: Index(['0', 'tcp', 'ftp_data', 'SF', '491', '0.1', '0.2', '0.3', '0.4', '0.5',\n",
      "       '0.6', '0.7', '0.8', '0.9', '0.10', '0.11', '0.12', '0.13', '0.14',\n",
      "       '0.15', '0.16', '0.18', '2', '2.1', '0.19', '0.20', '0.21', '0.22', '1',\n",
      "       '0.23', '0.24', '150', '25', '0.17', '0.03', '0.17.1', '0.25', '0.26',\n",
      "       '0.27', '0.05', '0.28', 'label'],\n",
      "      dtype='object')\n",
      "Test columns: Index(['0', 'tcp', 'private', 'REJ', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6',\n",
      "       '0.7', '0.8', '0.9', '0.10', '0.11', '0.12', '0.13', '0.14', '0.15',\n",
      "       '0.16', '0.17', '0.18', '229', '10', '0.19', '0.20', '1', '1.1', '0.04',\n",
      "       '0.06', '0.21', '255', '10.1', '0.04.1', '0.06.1', '0.22', '0.23',\n",
      "       '0.24', '0.25', '1.2', '1.3', 'neptune'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Train columns:\", train.columns)\n",
    "print(\"Test columns:\", test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d14bbbf-3715-410a-9468-eb7ce173bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125972 entries, 0 to 125971\n",
      "Data columns (total 42 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   0         125972 non-null  int64  \n",
      " 1   tcp       125972 non-null  object \n",
      " 2   ftp_data  125972 non-null  object \n",
      " 3   SF        125972 non-null  object \n",
      " 4   491       125972 non-null  int64  \n",
      " 5   0.1       125972 non-null  int64  \n",
      " 6   0.2       125972 non-null  int64  \n",
      " 7   0.3       125972 non-null  int64  \n",
      " 8   0.4       125972 non-null  int64  \n",
      " 9   0.5       125972 non-null  int64  \n",
      " 10  0.6       125972 non-null  int64  \n",
      " 11  0.7       125972 non-null  int64  \n",
      " 12  0.8       125972 non-null  int64  \n",
      " 13  0.9       125972 non-null  int64  \n",
      " 14  0.10      125972 non-null  int64  \n",
      " 15  0.11      125972 non-null  int64  \n",
      " 16  0.12      125972 non-null  int64  \n",
      " 17  0.13      125972 non-null  int64  \n",
      " 18  0.14      125972 non-null  int64  \n",
      " 19  0.15      125972 non-null  int64  \n",
      " 20  0.16      125972 non-null  int64  \n",
      " 21  0.18      125972 non-null  int64  \n",
      " 22  2         125972 non-null  int64  \n",
      " 23  2.1       125972 non-null  int64  \n",
      " 24  0.19      125972 non-null  float64\n",
      " 25  0.20      125972 non-null  float64\n",
      " 26  0.21      125972 non-null  float64\n",
      " 27  0.22      125972 non-null  float64\n",
      " 28  1         125972 non-null  float64\n",
      " 29  0.23      125972 non-null  float64\n",
      " 30  0.24      125972 non-null  float64\n",
      " 31  150       125972 non-null  int64  \n",
      " 32  25        125972 non-null  int64  \n",
      " 33  0.17      125972 non-null  float64\n",
      " 34  0.03      125972 non-null  float64\n",
      " 35  0.17.1    125972 non-null  float64\n",
      " 36  0.25      125972 non-null  float64\n",
      " 37  0.26      125972 non-null  float64\n",
      " 38  0.27      125972 non-null  float64\n",
      " 39  0.05      125972 non-null  float64\n",
      " 40  0.28      125972 non-null  float64\n",
      " 41  label     125972 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92fca5f1-c6be-46b9-b801-163d259afb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 42)\n",
      "Dimensions of the Test set: (22544, 42)\n",
      "Feature Mapping Shape: (125973, 1000)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable tanh method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'tanh'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(bls_features)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Train the BLS model\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m model, mapped_features_train, enhanced_features_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_bls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Predict on training set\u001b[39;00m\n\u001b[1;32m     81\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
      "Cell \u001b[0;32mIn[49], line 66\u001b[0m, in \u001b[0;36mtrain_bls\u001b[0;34m(X, y, n_mapped, n_enhancement, reg)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_bls\u001b[39m(X, y, n_mapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_enhancement\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m     mapped_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_mapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     enhanced_features \u001b[38;5;241m=\u001b[39m enhancement_nodes(mapped_features, n_enhancement_nodes\u001b[38;5;241m=\u001b[39mn_enhancement)\n\u001b[1;32m     68\u001b[0m     bls_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([mapped_features, enhanced_features], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 55\u001b[0m, in \u001b[0;36mfeature_mapping\u001b[0;34m(X, n_nodes)\u001b[0m\n\u001b[1;32m     53\u001b[0m Z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Z)  \u001b[38;5;66;03m# Ensure Z is an array\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Mapping Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Z\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Debugging statement to check dimensions\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type float which has no callable tanh method"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Column names as you provided\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "# Load dataset with explicit column names\n",
    "train = pd.read_csv(train_url, header=None, names=col_names)\n",
    "test = pd.read_csv(test_url, header=None, names=col_names)\n",
    "\n",
    "print('Dimensions of the Training set:', train.shape)\n",
    "print('Dimensions of the Test set:', test.shape)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    # Convert 'label' to binary classes ('normal' and 'anomalous')\n",
    "    df['label'] = df['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "    df = pd.get_dummies(df, columns=['protocol_type', 'service', 'flag'])  # One-hot encoding for categorical\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing to both train and test datasets\n",
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)\n",
    "\n",
    "# Split data into features and labels\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Define BLS-specific functions\n",
    "def feature_mapping(X, n_nodes=1000):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes).reshape(1, n_nodes)  # Ensures bias is 2D\n",
    "    Z = np.dot(X, W) + bias  # Linear mapping\n",
    "    Z = np.array(Z)  # Ensure Z is an array\n",
    "    print(\"Feature Mapping Shape:\", Z.shape)  # Debugging statement to check dimensions\n",
    "    return np.tanh(Z)  # Apply non-linear transformation\n",
    "\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes).reshape(1, n_enhancement_nodes)  # Ensure 2D for broadcasting\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    enhancement = np.array(enhancement)  # Ensure enhancement is an array\n",
    "    print(\"Enhancement Nodes Shape:\", enhancement.shape)  # Debugging statement to check dimensions\n",
    "    return np.tanh(enhancement)\n",
    "def train_bls(X, y, n_mapped=1000, n_enhancement=500, reg=0.01):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    model = Ridge(alpha=reg, fit_intercept=False)\n",
    "    model.fit(bls_features, y)\n",
    "    return model, mapped_features, enhanced_features\n",
    "\n",
    "def predict_bls(model, X, mapped_features, enhanced_features):\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    return model.predict(bls_features)\n",
    "\n",
    "# Train the BLS model\n",
    "model, mapped_features_train, enhanced_features_train = train_bls(X_train, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_pred_train = predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
    "y_pred_train = np.where(y_pred_train >= 0.5, 1, 0)  # Convert to binary\n",
    "\n",
    "# Training accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test the model\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=1000)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=500)\n",
    "y_pred_test = predict_bls(model, X_test, mapped_features_test, enhanced_features_test)\n",
    "y_pred_test = np.where(y_pred_test >= 0.5, 1, 0)\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4152285-887c-467d-8564-8da834552437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.986679685329396\n",
      "Test Accuracy: 0.7862402413058907\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Set column names and load datasets\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "train = pd.read_csv(train_url, header=None, names=col_names)\n",
    "test = pd.read_csv(test_url, header=None, names=col_names)\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = df['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "    df = pd.get_dummies(df, columns=['protocol_type', 'service', 'flag'])\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "    return df\n",
    "\n",
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)\n",
    "\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Feature Mapping with row-wise np.tanh\n",
    "def feature_mapping(X, n_nodes=1000):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes).reshape(1, n_nodes)\n",
    "    Z = np.dot(X, W) + bias\n",
    "    Z = np.array(Z, dtype=np.float64)  # Ensure all values are float64\n",
    "    return np.vectorize(np.tanh)(Z)  # Apply tanh element-wise\n",
    "\n",
    "# Enhancement Nodes with row-wise np.tanh\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes).reshape(1, n_enhancement_nodes)\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    enhancement = np.array(enhancement, dtype=np.float64)\n",
    "    return np.vectorize(np.tanh)(enhancement)\n",
    "\n",
    "# BLS Training\n",
    "def train_bls(X, y, n_mapped=1000, n_enhancement=500, reg=0.01):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    model = Ridge(alpha=reg, fit_intercept=False)\n",
    "    model.fit(bls_features, y)\n",
    "    return model, mapped_features, enhanced_features\n",
    "\n",
    "# Prediction\n",
    "def predict_bls(model, X, mapped_features, enhanced_features):\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    return model.predict(bls_features)\n",
    "\n",
    "# Train and Test\n",
    "model, mapped_features_train, enhanced_features_train = train_bls(X_train, y_train)\n",
    "y_pred_train = predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
    "y_pred_train = np.where(y_pred_train >= 0.5, 1, 0)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=1000)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=500)\n",
    "y_pred_test = predict_bls(model, X_test, mapped_features_test, enhanced_features_test)\n",
    "y_pred_test = np.where(y_pred_test >= 0.5, 1, 0)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9b65f35-0e4c-4a16-8b6f-8e0a30b972e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.986679685329396\n",
      "Test Accuracy: 0.7862402413058907\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Set column names and load datasets\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "train = pd.read_csv(train_url, header=None, names=col_names)\n",
    "test = pd.read_csv(test_url, header=None, names=col_names)\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = df['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "    df = pd.get_dummies(df, columns=['protocol_type', 'service', 'flag'])\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "    return df\n",
    "\n",
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)\n",
    "\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Feature Mapping with row-wise np.tanh\n",
    "def feature_mapping(X, n_nodes=1000):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes).reshape(1, n_nodes)\n",
    "    Z = np.dot(X, W) + bias\n",
    "    Z = np.array(Z, dtype=np.float64)  # Ensure all values are float64\n",
    "    return np.vectorize(np.tanh)(Z)  # Apply tanh element-wise\n",
    "\n",
    "# Enhancement Nodes with row-wise np.tanh\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes).reshape(1, n_enhancement_nodes)\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    enhancement = np.array(enhancement, dtype=np.float64)\n",
    "    return np.vectorize(np.tanh)(enhancement)\n",
    "\n",
    "# BLS Training\n",
    "def train_bls(X, y, n_mapped=1000, n_enhancement=500, reg=0.01):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    model = Ridge(alpha=reg, fit_intercept=False)\n",
    "    model.fit(bls_features, y)\n",
    "    return model, mapped_features, enhanced_features\n",
    "\n",
    "# Prediction\n",
    "def predict_bls(model, X, mapped_features, enhanced_features):\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    return model.predict(bls_features)\n",
    "\n",
    "# Train and Test\n",
    "model, mapped_features_train, enhanced_features_train = train_bls(X_train, y_train)\n",
    "y_pred_train = predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
    "y_pred_train = np.where(y_pred_train >= 0.5, 1, 0)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=1000)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=500)\n",
    "y_pred_test = predict_bls(model, X_test, mapped_features_test, enhanced_features_test)\n",
    "y_pred_test = np.where(y_pred_test >= 0.5, 1, 0)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8f6cfcc-8ff7-4af2-8f1c-103b913322ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 116 features, but StandardScaler is expecting 122 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m     48\u001b[0m X_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m---> 49\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Reduce dimensions using PCA for feature selection\u001b[39;00m\n\u001b[1;32m     52\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)  \u001b[38;5;66;03m# Adjust n_components as needed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1045\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1042\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1044\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1045\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 116 features, but StandardScaler is expecting 122 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set column names and load datasets\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "train = pd.read_csv(train_url, header=None, names=col_names)\n",
    "test = pd.read_csv(test_url, header=None, names=col_names)\n",
    "\n",
    "# Preprocessing with feature scaling and label encoding\n",
    "def preprocess_data(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = df['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "    df = pd.get_dummies(df, columns=['protocol_type', 'service', 'flag'])  # One-hot encoding\n",
    "    df['label'] = label_encoder.fit_transform(df['label'])\n",
    "    return df\n",
    "\n",
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)\n",
    "\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Scale features for better generalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reduce dimensions using PCA for feature selection\n",
    "pca = PCA(n_components=30)  # Adjust n_components as needed\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Feature Mapping and Enhancement Functions\n",
    "def feature_mapping(X, n_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes).reshape(1, n_nodes)\n",
    "    Z = np.dot(X, W) + bias\n",
    "    return np.tanh(Z)\n",
    "\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=250):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes).reshape(1, n_enhancement_nodes)\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    return np.tanh(enhancement)\n",
    "\n",
    "# Ridge regression with cross-validation for regularization tuning\n",
    "def train_bls_with_cv(X, y, n_mapped=500, n_enhancement=250):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    \n",
    "    # Cross-validation for the best alpha (reg)\n",
    "    param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "    ridge = Ridge(fit_intercept=False)\n",
    "    grid = GridSearchCV(ridge, param_grid, scoring='accuracy', cv=5)\n",
    "    grid.fit(bls_features, y)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    return best_model, mapped_features, enhanced_features\n",
    "\n",
    "# Train the BLS model with cross-validated regularization\n",
    "model, mapped_features_train, enhanced_features_train = train_bls_with_cv(X_train, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_pred_train = model.predict(np.concatenate([mapped_features_train, enhanced_features_train], axis=1))\n",
    "y_pred_train = np.where(y_pred_train >= 0.5, 1, 0)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# Test the model on the test set\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=500)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=250)\n",
    "y_pred_test = model.predict(np.concatenate([mapped_features_test, enhanced_features_test], axis=1))\n",
    "y_pred_test = np.where(y_pred_test >= 0.5, 1, 0)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "train_accuracy, test_accuracy, grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "803de40d-c709-41a8-be0c-c9bdf4fc0b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 231, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 112, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9919982853468601\n",
      "Test Accuracy: 0.7892122072391767\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Column names and data loading\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "train = pd.read_csv(train_url, header=None, names=col_names)\n",
    "test = pd.read_csv(test_url, header=None, names=col_names)\n",
    "\n",
    "# Combine and encode to ensure consistency\n",
    "combined = pd.concat([train, test], keys=['train', 'test'])\n",
    "combined['label'] = combined['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "combined = pd.get_dummies(combined, columns=['protocol_type', 'service', 'flag'])\n",
    "\n",
    "# Separate back into train and test datasets\n",
    "train = combined.xs('train')\n",
    "test = combined.xs('test')\n",
    "\n",
    "# Split features and labels\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Scale features for better generalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Feature Mapping with fewer nodes to reduce complexity\n",
    "def feature_mapping(X, n_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes).reshape(1, n_nodes)\n",
    "    Z = np.dot(X, W) + bias\n",
    "    return np.tanh(Z)\n",
    "\n",
    "# Enhancement Nodes with fewer nodes for regularization\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=250):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes).reshape(1, n_enhancement_nodes)\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    return np.tanh(enhancement)\n",
    "\n",
    "# Ridge regression with cross-validation for regularization tuning\n",
    "def train_bls_with_cv(X, y, n_mapped=500, n_enhancement=250):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    \n",
    "    # Cross-validation for the best alpha (reg)\n",
    "    param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "    ridge = Ridge(fit_intercept=False)\n",
    "    grid = GridSearchCV(ridge, param_grid, scoring='accuracy', cv=5)\n",
    "    grid.fit(bls_features, y)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    return best_model, mapped_features, enhanced_features\n",
    "\n",
    "# Train the BLS model with cross-validated regularization\n",
    "model, mapped_features_train, enhanced_features_train = train_bls_with_cv(X_train, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "def predict_bls(model, X, mapped_features, enhanced_features):\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    return model.predict(bls_features)\n",
    "\n",
    "# Predict on training set and evaluate accuracy\n",
    "y_pred_train = predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
    "y_pred_train = np.where(y_pred_train >= 0.5, 1, 0)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test the model on the test set and evaluate accuracy\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=500)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=250)\n",
    "y_pred_test = predict_bls(model, X_test, mapped_features_test, enhanced_features_test)\n",
    "y_pred_test = np.where(y_pred_test >= 0.5, 1, 0)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3125b046-ec31-4eae-8238-d6473b770bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9919347796750098\n",
      "Test Accuracy: 0.7877927608232789\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Column names and data loading\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\n",
    "    \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'\n",
    "\n",
    "train = pd.read_csv(train_url, header=None, names=col_names)\n",
    "test = pd.read_csv(test_url, header=None, names=col_names)\n",
    "\n",
    "# Combine and encode to ensure consistency\n",
    "combined = pd.concat([train, test], keys=['train', 'test'])\n",
    "combined['label'] = combined['label'].apply(lambda x: 'normal' if x == 'normal' else 'anomalous')\n",
    "combined = pd.get_dummies(combined, columns=['protocol_type', 'service', 'flag'])\n",
    "\n",
    "# Separate back into train and test datasets\n",
    "train = combined.xs('train')\n",
    "test = combined.xs('test')\n",
    "\n",
    "# Split features and labels\n",
    "X_train = train.drop('label', axis=1).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop('label', axis=1).values\n",
    "y_test = test['label'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Scale features for better generalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Feature Mapping with fewer nodes to reduce complexity\n",
    "def feature_mapping(X, n_nodes=500):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (X.shape[1], n_nodes))\n",
    "    bias = np.random.normal(0, 1, n_nodes).reshape(1, n_nodes)\n",
    "    Z = np.dot(X, W) + bias\n",
    "    return np.tanh(Z)\n",
    "\n",
    "# Enhancement Nodes with fewer nodes for regularization\n",
    "def enhancement_nodes(mapped_features, n_enhancement_nodes=250):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, 1, (mapped_features.shape[1], n_enhancement_nodes))\n",
    "    bias = np.random.normal(0, 1, n_enhancement_nodes).reshape(1, n_enhancement_nodes)\n",
    "    enhancement = np.dot(mapped_features, W) + bias\n",
    "    return np.tanh(enhancement)\n",
    "\n",
    "# Ridge regression with cross-validation for regularization tuning\n",
    "def train_bls_with_cv(X, y, n_mapped=500, n_enhancement=250):\n",
    "    mapped_features = feature_mapping(X, n_nodes=n_mapped)\n",
    "    enhanced_features = enhancement_nodes(mapped_features, n_enhancement_nodes=n_enhancement)\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    \n",
    "    # Cross-validation for the best alpha using MSE scoring\n",
    "    param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "    ridge = Ridge(fit_intercept=False)\n",
    "    grid = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    grid.fit(bls_features, y)\n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    return best_model, mapped_features, enhanced_features\n",
    "\n",
    "# Train the BLS model with cross-validated regularization\n",
    "model, mapped_features_train, enhanced_features_train = train_bls_with_cv(X_train, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "def predict_bls(model, X, mapped_features, enhanced_features):\n",
    "    bls_features = np.concatenate([mapped_features, enhanced_features], axis=1)\n",
    "    predictions = model.predict(bls_features)\n",
    "    # Convert continuous predictions to binary labels\n",
    "    return np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "# Predict on training set and evaluate accuracy\n",
    "y_pred_train = predict_bls(model, X_train, mapped_features_train, enhanced_features_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Test the model on the test set and evaluate accuracy\n",
    "mapped_features_test = feature_mapping(X_test, n_nodes=500)\n",
    "enhanced_features_test = enhancement_nodes(mapped_features_test, n_enhancement_nodes=250)\n",
    "y_pred_test = predict_bls(model, X_test, mapped_features_test, enhanced_features_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "697f19fa-5734-4133-89a0-6592e3077cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best cross-validation score for Gradient Boosting: 0.9987933928015288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:20:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:20:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:20:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:20:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:20:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation score for XGBoost: 0.9992\n",
      "Standard deviation of cross-validation scores for XGBoost: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:21:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:26:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:26:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:26:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:26:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:26:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:27:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:31:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:31:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:31:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:31:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:31:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:32:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:37:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:37:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:37:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:37:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:37:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:38:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:42:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:47:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:47:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:48:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py311_env/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [13:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Cross-Validation Score: 0.9991903048261349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Gradient Boosting Model with hyperparameter tuning\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "param_grid_gbc = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3, 5],\n",
    "}\n",
    "grid_gbc = GridSearchCV(gbc, param_grid_gbc, cv=5)\n",
    "grid_gbc.fit(X_train, y_train)\n",
    "print(\"Best parameters for Gradient Boosting:\", grid_gbc.best_params_)\n",
    "print(\"Best cross-validation score for Gradient Boosting:\", grid_gbc.best_score_)\n",
    "\n",
    "# Cross-validation for XGBoost model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_scores = cross_val_score(xgb, X_train, y_train, cv=5)\n",
    "print(f\"Mean cross-validation score for XGBoost: {np.mean(xgb_scores):.4f}\")\n",
    "print(f\"Standard deviation of cross-validation scores for XGBoost: {np.std(xgb_scores):.4f}\")\n",
    "\n",
    "# Stacking Ensemble\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gbc', grid_gbc.best_estimator_),\n",
    "    ('xgb', xgb)\n",
    "]\n",
    "\n",
    "stacked_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacked_model.fit(X_train, y_train)\n",
    "stacked_score = cross_val_score(stacked_model, X_train, y_train, cv=5).mean()\n",
    "print(\"Stacked Model Cross-Validation Score:\", stacked_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f21cce-2d11-4a03-ad1d-05e207b5f993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
